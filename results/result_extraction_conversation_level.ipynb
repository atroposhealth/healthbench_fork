{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a71b73",
   "metadata": {},
   "source": [
    "This notebook exists to capture the conversation-level metrics for all of the runs. There is a separate notebook for capturing the run-level metrics. (Each run comprises 5000 conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f92541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53174f45",
   "metadata": {},
   "source": [
    "Each conversation is tagged with a \"theme\", but that tag is only present in the input data. Addionally, each rubric item is tagged with an \"axis\". The axis is available in the results JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec35715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the theme for each conversation. This dataframe will be joined into\n",
    "# the rest of the results later on.\n",
    "conversation_input_file = Path(\"inputs/2025-05-07-06-14-12_oss_eval.jsonl\")\n",
    "conversation_lines = conversation_input_file.read_text().split(\"\\n\")\n",
    "\n",
    "\n",
    "def theme_from_conversation(conversation: dict) -> str:\n",
    "    for tag in conversation[\"example_tags\"]:\n",
    "        if tag.startswith(\"theme\"):\n",
    "            return tag.split(\":\")[1]\n",
    "    raise ValueError(\n",
    "        f\"Conversation does not have theme: {conversation['example_tags']}. {conversation['prompt_id']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "rows = []\n",
    "for conversation_line in conversation_lines:\n",
    "    if conversation_line == \"\":\n",
    "        continue\n",
    "    conversation = json.loads(conversation_line)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"conversation_id\": conversation[\"prompt_id\"],\n",
    "            \"theme\": theme_from_conversation(conversation),\n",
    "        }\n",
    "    )\n",
    "themes = pl.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3071d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dirs = [\n",
    "    Path(\"5df4ba309cb03369f6663786ae6a9904385524a9/maverick\"),\n",
    "    Path(\"5df4ba309cb03369f6663786ae6a9904385524a9/scout\"),\n",
    "    Path(\"328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3\"),\n",
    "    Path(\"9252fc34f9bc391262e8b71138ee3b86e7d0ad7a/o3\"),\n",
    "    Path(\"9eb82b46b5ef7faf6ec102a989421543e84d4228/llama-3.1-8b\"),\n",
    "    Path(\"66a515a50edfaa2c8f21674d4141a124b50ef286/llama-4-maverick-rag\"),\n",
    "    Path(\"66a515a50edfaa2c8f21674d4141a124b50ef286/llama-4-scout-rag\"),\n",
    "]\n",
    "result_files = []\n",
    "for path in results_dirs:\n",
    "    files = list(path.glob(\"*_allresults.json\"))\n",
    "    result_files.extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f16de7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_153644_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_211736_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_165626_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251023_212754_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251026_154748_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_144601_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_104623_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_140350_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_091851_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251026_005928_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_170346_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_115249_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251023_153707_allresults.json'),\n",
       " PosixPath('5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_161630_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_035734_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_225911_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_004114_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_234852_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_021752_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_205737_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_012947_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_162900_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_030629_allresults.json'),\n",
       " PosixPath('328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_213700_allresults.json'),\n",
       " PosixPath('9252fc34f9bc391262e8b71138ee3b86e7d0ad7a/o3/healthbench_o3_20251029_151631_allresults.json'),\n",
       " PosixPath('9eb82b46b5ef7faf6ec102a989421543e84d4228/llama-3.1-8b/healthbench_llama-3.1-8b_20251030_123814_allresults.json'),\n",
       " PosixPath('66a515a50edfaa2c8f21674d4141a124b50ef286/llama-4-maverick-rag/healthbench_llama-4-maverick-rag_20251118_161039_allresults.json'),\n",
       " PosixPath('66a515a50edfaa2c8f21674d4141a124b50ef286/llama-4-scout-rag/healthbench_llama-4-scout-rag_20251118_204328_allresults.json')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db6d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name_and_execution_time(results: Path) -> tuple[str, str]:\n",
    "    _, model, day, time, _ = results.stem.split(\"_\")\n",
    "    return model, f\"{day}_{time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4c371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_from_rubric_item(rubric_item: dict) -> str:\n",
    "    for tag in rubric_item[\"tags\"]:\n",
    "        if tag.startswith(\"axis\"):\n",
    "            return tag.split(\":\")[1]\n",
    "    raise ValueError(\n",
    "        f\"Unable to find axis for rubric item. Tags: {rubric_item['tags']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "rows = []\n",
    "for filepath in result_files:\n",
    "    model, run_id = get_model_name_and_execution_time(filepath)\n",
    "    run_results = json.loads(filepath.read_text())\n",
    "    for conversation_results in run_results[\"metadata\"][\"example_level_metadata\"]:\n",
    "        for rubric_item_index, rubric_item in enumerate(\n",
    "            conversation_results[\"rubric_items\"]\n",
    "        ):\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"model\": model,\n",
    "                    \"run_id\": run_id,\n",
    "                    \"conversation_id\": conversation_results[\"prompt_id\"],\n",
    "                    \"rubric_criterion_index\": rubric_item_index,\n",
    "                    \"axis\": axis_from_rubric_item(rubric_item),\n",
    "                    \"points\": rubric_item[\"points\"],\n",
    "                    \"criterion_met\": rubric_item[\"criteria_met\"],\n",
    "                }\n",
    "            )\n",
    "conversation_results = pl.DataFrame(rows).join(themes, on=\"conversation_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac05b1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_602_636, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>conversation_id</th><th>rubric_criterion_index</th><th>axis</th><th>points</th><th>criterion_met</th><th>theme</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>0</td><td>&quot;completeness&quot;</td><td>10</td><td>true</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>1</td><td>&quot;completeness&quot;</td><td>9</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>2</td><td>&quot;context_awareness&quot;</td><td>7</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>3</td><td>&quot;accuracy&quot;</td><td>-10</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>4</td><td>&quot;completeness&quot;</td><td>8</td><td>true</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;e1cf80cd-965e-4a64-b2e3-a95497…</td><td>13</td><td>&quot;context_awareness&quot;</td><td>5</td><td>true</td><td>&quot;emergency_referrals&quot;</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>0</td><td>&quot;accuracy&quot;</td><td>9</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>1</td><td>&quot;completeness&quot;</td><td>8</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>2</td><td>&quot;completeness&quot;</td><td>7</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>3</td><td>&quot;accuracy&quot;</td><td>-9</td><td>false</td><td>&quot;global_health&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_602_636, 8)\n",
       "┌────────────┬────────────┬────────────┬────────────┬────────────┬────────┬────────────┬───────────┐\n",
       "│ model      ┆ run_id     ┆ conversati ┆ rubric_cri ┆ axis       ┆ points ┆ criterion_ ┆ theme     │\n",
       "│ ---        ┆ ---        ┆ on_id      ┆ terion_ind ┆ ---        ┆ ---    ┆ met        ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ ex         ┆ str        ┆ i64    ┆ ---        ┆ str       │\n",
       "│            ┆            ┆ str        ┆ ---        ┆            ┆        ┆ bool       ┆           │\n",
       "│            ┆            ┆            ┆ i64        ┆            ┆        ┆            ┆           │\n",
       "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════╪════════════╪═══════════╡\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 0          ┆ completene ┆ 10     ┆ true       ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 1          ┆ completene ┆ 9      ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 2          ┆ context_aw ┆ 7      ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ areness    ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 3          ┆ accuracy   ┆ -10    ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆            ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 4          ┆ completene ┆ 8      ┆ true       ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …          ┆ …          ┆ …      ┆ …          ┆ …         │\n",
       "│ llama-4-sc ┆ 20251118_2 ┆ e1cf80cd-9 ┆ 13         ┆ context_aw ┆ 5      ┆ true       ┆ emergency │\n",
       "│ out-rag    ┆ 04328      ┆ 65e-4a64-b ┆            ┆ areness    ┆        ┆            ┆ _referral │\n",
       "│            ┆            ┆ 2e3-a95497 ┆            ┆            ┆        ┆            ┆ s         │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-sc ┆ 20251118_2 ┆ 68b20b72-f ┆ 0          ┆ accuracy   ┆ 9      ┆ false      ┆ global_he │\n",
       "│ out-rag    ┆ 04328      ┆ 599-4cd0-a ┆            ┆            ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-sc ┆ 20251118_2 ┆ 68b20b72-f ┆ 1          ┆ completene ┆ 8      ┆ false      ┆ global_he │\n",
       "│ out-rag    ┆ 04328      ┆ 599-4cd0-a ┆            ┆ ss         ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-sc ┆ 20251118_2 ┆ 68b20b72-f ┆ 2          ┆ completene ┆ 7      ┆ false      ┆ global_he │\n",
       "│ out-rag    ┆ 04328      ┆ 599-4cd0-a ┆            ┆ ss         ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-sc ┆ 20251118_2 ┆ 68b20b72-f ┆ 3          ┆ accuracy   ┆ -9     ┆ false      ┆ global_he │\n",
       "│ out-rag    ┆ 04328      ┆ 599-4cd0-a ┆            ┆            ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴────────────┴────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1859eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "conversation_results.write_csv(\n",
    "    f\"healthbench_granular_data_{timestamp}.tsv\", separator=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fd349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586b0f2c",
   "metadata": {},
   "source": [
    "## Calculating Scores\n",
    "The rest of the cells exist to calculate the overall, theme, and axis scores to reproduce what is in the theme_data.csv, axis_data.csv, and JSON result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20044ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_confidence_intervals(scores: pl.Series) -> dict:\n",
    "    scores_np = scores.to_numpy()\n",
    "    mean = np.clip(np.mean(scores_np), 0, 1).item()\n",
    "    lower, upper = np.percentile(\n",
    "        [np.mean(np.random.choice(scores_np, len(scores_np))) for _ in range(1000)],\n",
    "        [2.5, 97.5],\n",
    "    )\n",
    "    return {\"mean\": mean, \"lower_ci\": float(lower), \"upper_ci\": float(upper)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca8a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_results = (\n",
    "    conversation_results.vstack(\n",
    "        # Add another copy of the DF where all conversations are duplicated\n",
    "        # under the \"all\" theme, in order to calculate the overall score and CIs\n",
    "        conversation_results.with_columns(pl.lit(\"all\").alias(\"theme\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Determine whether the points should actually be awarded for each criterion\n",
    "        pl.when(\"criterion_met\")\n",
    "        .then(\"points\")\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"criterion_points_awarded\"),\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"theme\", \"conversation_id\")\n",
    "    .agg(\n",
    "        # Calculate the total number of points possible for the conversation\n",
    "        pl.col(\"points\")\n",
    "        .filter(pl.col(\"points\") > 0)\n",
    "        .sum()\n",
    "        .alias(\"conversation_points_possible\"),\n",
    "        # Sum the points awarded for this conversation, note that the score for an\n",
    "        # individual conversation can be negative, but the overall/theme/axis score\n",
    "        # is clipped to a minimum of 0\n",
    "        pl.col(\"criterion_points_awarded\").sum().alias(\"conversation_points_awarded\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Calculate the score for each conversation\n",
    "        (\n",
    "            pl.col(\"conversation_points_awarded\")\n",
    "            / pl.col(\"conversation_points_possible\")\n",
    "        ).alias(\"conversation_score\")\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"theme\")\n",
    "    .agg(\n",
    "        # Calculate a mean with CI at the run level\n",
    "        pl.col(\"conversation_score\")\n",
    "        .map_batches(function=get_mean_and_confidence_intervals, returns_scalar=True)\n",
    "        .alias(\"results_struct\")\n",
    "    )\n",
    "    .unnest(\"results_struct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7982d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (224, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>theme</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_115249&quot;</td><td>&quot;communication&quot;</td><td>0.325642</td><td>0.29798</td><td>0.352324</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_021752&quot;</td><td>&quot;global_health&quot;</td><td>0.145488</td><td>0.124821</td><td>0.16389</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;complex_responses&quot;</td><td>0.291784</td><td>0.249196</td><td>0.331069</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;emergency_referrals&quot;</td><td>0.324698</td><td>0.283491</td><td>0.363218</td></tr><tr><td>&quot;llama-4-maverick-rag&quot;</td><td>&quot;20251118_161039&quot;</td><td>&quot;context_seeking&quot;</td><td>0.09815</td><td>0.072109</td><td>0.123259</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_234852&quot;</td><td>&quot;all&quot;</td><td>0.246677</td><td>0.235073</td><td>0.257951</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_225911&quot;</td><td>&quot;context_seeking&quot;</td><td>0.149962</td><td>0.122349</td><td>0.178624</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_012947&quot;</td><td>&quot;global_health&quot;</td><td>0.147815</td><td>0.128565</td><td>0.167432</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_104623&quot;</td><td>&quot;all&quot;</td><td>0.250181</td><td>0.239498</td><td>0.260833</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251026_005928&quot;</td><td>&quot;global_health&quot;</td><td>0.145747</td><td>0.126099</td><td>0.166516</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (224, 6)\n",
       "┌──────────────────────┬─────────────────┬─────────────────────┬──────────┬──────────┬──────────┐\n",
       "│ model                ┆ run_id          ┆ theme               ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---                  ┆ ---             ┆ ---                 ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str                  ┆ str             ┆ str                 ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞══════════════════════╪═════════════════╪═════════════════════╪══════════╪══════════╪══════════╡\n",
       "│ llama-4-scout        ┆ 20251027_115249 ┆ communication       ┆ 0.325642 ┆ 0.29798  ┆ 0.352324 │\n",
       "│ llama-3.3-70b        ┆ 20251029_021752 ┆ global_health       ┆ 0.145488 ┆ 0.124821 ┆ 0.16389  │\n",
       "│ llama-4-maverick     ┆ 20251027_153644 ┆ complex_responses   ┆ 0.291784 ┆ 0.249196 ┆ 0.331069 │\n",
       "│ llama-3.1-8b         ┆ 20251030_123814 ┆ emergency_referrals ┆ 0.324698 ┆ 0.283491 ┆ 0.363218 │\n",
       "│ llama-4-maverick-rag ┆ 20251118_161039 ┆ context_seeking     ┆ 0.09815  ┆ 0.072109 ┆ 0.123259 │\n",
       "│ …                    ┆ …               ┆ …                   ┆ …        ┆ …        ┆ …        │\n",
       "│ llama-3.3-70b        ┆ 20251028_234852 ┆ all                 ┆ 0.246677 ┆ 0.235073 ┆ 0.257951 │\n",
       "│ llama-3.3-70b        ┆ 20251028_225911 ┆ context_seeking     ┆ 0.149962 ┆ 0.122349 ┆ 0.178624 │\n",
       "│ llama-3.3-70b        ┆ 20251029_012947 ┆ global_health       ┆ 0.147815 ┆ 0.128565 ┆ 0.167432 │\n",
       "│ llama-4-scout        ┆ 20251027_104623 ┆ all                 ┆ 0.250181 ┆ 0.239498 ┆ 0.260833 │\n",
       "│ llama-4-scout        ┆ 20251026_005928 ┆ global_health       ┆ 0.145747 ┆ 0.126099 ┆ 0.166516 │\n",
       "└──────────────────────┴─────────────────┴─────────────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8fefeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>theme</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;all&quot;</td><td>0.248817</td><td>0.238329</td><td>0.259538</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;communication&quot;</td><td>0.327913</td><td>0.29888</td><td>0.356458</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;complex_responses&quot;</td><td>0.277469</td><td>0.231303</td><td>0.3219</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;context_seeking&quot;</td><td>0.146587</td><td>0.118933</td><td>0.173854</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;emergency_referrals&quot;</td><td>0.411371</td><td>0.374932</td><td>0.443217</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;global_health&quot;</td><td>0.144872</td><td>0.123802</td><td>0.164027</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;health_data_tasks&quot;</td><td>0.289996</td><td>0.251364</td><td>0.327144</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;hedging&quot;</td><td>0.242986</td><td>0.221445</td><td>0.266253</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 6)\n",
       "┌───────────────┬─────────────────┬─────────────────────┬──────────┬──────────┬──────────┐\n",
       "│ model         ┆ run_id          ┆ theme               ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---           ┆ ---             ┆ ---                 ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str           ┆ str             ┆ str                 ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═══════════════╪═════════════════╪═════════════════════╪══════════╪══════════╪══════════╡\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ all                 ┆ 0.248817 ┆ 0.238329 ┆ 0.259538 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ communication       ┆ 0.327913 ┆ 0.29888  ┆ 0.356458 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ complex_responses   ┆ 0.277469 ┆ 0.231303 ┆ 0.3219   │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ context_seeking     ┆ 0.146587 ┆ 0.118933 ┆ 0.173854 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ emergency_referrals ┆ 0.411371 ┆ 0.374932 ┆ 0.443217 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ global_health       ┆ 0.144872 ┆ 0.123802 ┆ 0.164027 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ health_data_tasks   ┆ 0.289996 ┆ 0.251364 ┆ 0.327144 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ hedging             ┆ 0.242986 ┆ 0.221445 ┆ 0.266253 │\n",
       "└───────────────┴─────────────────┴─────────────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results.filter(\n",
    "    (pl.col(\"model\") == \"llama-4-scout\") & (pl.col(\"run_id\") == \"20251024_161630\")\n",
    ").sort(by=\"theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2823cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_results = (\n",
    "    conversation_results.vstack(\n",
    "        # Add another copy of the DF where all conversations a duplicated under the\n",
    "        # \"all\" theme, in order to calculate the overall score and CI\n",
    "        conversation_results.with_columns(pl.lit(\"all\").alias(\"axis\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Determine whether the points should actually be awarded for each criterion\n",
    "        pl.when(\"criterion_met\")\n",
    "        .then(\"points\")\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"criterion_points_awarded\"),\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"axis\", \"conversation_id\")\n",
    "    .agg(\n",
    "        # Calculate the total number of points possible for the conversation\n",
    "        pl.col(\"points\")\n",
    "        .filter(pl.col(\"points\") > 0)\n",
    "        .sum()\n",
    "        .alias(\"conversation_points_possible\"),\n",
    "        # Sum the points awarded for this quesiton, note that the score for an\n",
    "        # individual question can be negative, but the overall/theme/axis score\n",
    "        # is clipped to a minimum of 0\n",
    "        pl.col(\"criterion_points_awarded\").sum().alias(\"conversation_points_awarded\"),\n",
    "    )\n",
    "    # Filter out questions that do not have any criteria for a given axis\n",
    "    .filter(pl.col(\"conversation_points_possible\") > 0)\n",
    "    .with_columns(\n",
    "        # Calculate the score for each conversation\n",
    "        (\n",
    "            pl.col(\"conversation_points_awarded\")\n",
    "            / pl.col(\"conversation_points_possible\")\n",
    "        ).alias(\"conversation_score\")\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"axis\")\n",
    "    .agg(\n",
    "        # Calculate a mean with CI at the run level\n",
    "        pl.col(\"conversation_score\")\n",
    "        .map_batches(function=get_mean_and_confidence_intervals, returns_scalar=True)\n",
    "        .alias(\"results_struct\")\n",
    "    )\n",
    "    .unnest(\"results_struct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fda0a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>axis</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_115249&quot;</td><td>&quot;all&quot;</td><td>0.250344</td><td>0.239762</td><td>0.261344</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;all&quot;</td><td>0.248817</td><td>0.237675</td><td>0.259582</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251026_154748&quot;</td><td>&quot;all&quot;</td><td>0.251353</td><td>0.241523</td><td>0.261722</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_170346&quot;</td><td>&quot;all&quot;</td><td>0.2482</td><td>0.237123</td><td>0.259175</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251023_153707&quot;</td><td>&quot;all&quot;</td><td>0.249285</td><td>0.239443</td><td>0.259903</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251026_005928&quot;</td><td>&quot;all&quot;</td><td>0.247284</td><td>0.235884</td><td>0.258429</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_140350&quot;</td><td>&quot;all&quot;</td><td>0.249213</td><td>0.238991</td><td>0.2599</td></tr><tr><td>&quot;llama-4-scout-rag&quot;</td><td>&quot;20251118_204328&quot;</td><td>&quot;all&quot;</td><td>0.223146</td><td>0.212068</td><td>0.233759</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_091851&quot;</td><td>&quot;all&quot;</td><td>0.251315</td><td>0.240097</td><td>0.261721</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_104623&quot;</td><td>&quot;all&quot;</td><td>0.250181</td><td>0.239609</td><td>0.260161</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 6)\n",
       "┌───────────────────┬─────────────────┬──────┬──────────┬──────────┬──────────┐\n",
       "│ model             ┆ run_id          ┆ axis ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---               ┆ ---             ┆ ---  ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str               ┆ str             ┆ str  ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═══════════════════╪═════════════════╪══════╪══════════╪══════════╪══════════╡\n",
       "│ llama-4-scout     ┆ 20251027_115249 ┆ all  ┆ 0.250344 ┆ 0.239762 ┆ 0.261344 │\n",
       "│ llama-4-scout     ┆ 20251024_161630 ┆ all  ┆ 0.248817 ┆ 0.237675 ┆ 0.259582 │\n",
       "│ llama-4-scout     ┆ 20251026_154748 ┆ all  ┆ 0.251353 ┆ 0.241523 ┆ 0.261722 │\n",
       "│ llama-4-scout     ┆ 20251024_170346 ┆ all  ┆ 0.2482   ┆ 0.237123 ┆ 0.259175 │\n",
       "│ llama-4-scout     ┆ 20251023_153707 ┆ all  ┆ 0.249285 ┆ 0.239443 ┆ 0.259903 │\n",
       "│ …                 ┆ …               ┆ …    ┆ …        ┆ …        ┆ …        │\n",
       "│ llama-4-scout     ┆ 20251026_005928 ┆ all  ┆ 0.247284 ┆ 0.235884 ┆ 0.258429 │\n",
       "│ llama-4-scout     ┆ 20251027_140350 ┆ all  ┆ 0.249213 ┆ 0.238991 ┆ 0.2599   │\n",
       "│ llama-4-scout-rag ┆ 20251118_204328 ┆ all  ┆ 0.223146 ┆ 0.212068 ┆ 0.233759 │\n",
       "│ llama-4-scout     ┆ 20251027_091851 ┆ all  ┆ 0.251315 ┆ 0.240097 ┆ 0.261721 │\n",
       "│ llama-4-scout     ┆ 20251027_104623 ┆ all  ┆ 0.250181 ┆ 0.239609 ┆ 0.260161 │\n",
       "└───────────────────┴─────────────────┴──────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis_results.filter(\n",
    "    ((pl.col(\"model\") == \"llama-4-scout\") | (pl.col(\"model\") == \"llama-4-scout-rag\"))\n",
    "    & (pl.col(\"axis\") == \"all\")\n",
    ").sort(\"axis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "026be5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = axis_results.select(\n",
    "    \"model\",\n",
    "    \"run_id\",\n",
    "    pl.lit(\"axis\").alias(\"theme_or_axis\"),\n",
    "    pl.col(\"axis\").alias(\"theme_or_axis_name\"),\n",
    "    \"mean\",\n",
    "    \"lower_ci\",\n",
    "    \"upper_ci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d00e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-evals (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
