{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a71b73",
   "metadata": {},
   "source": [
    "This notebook exists to capture the conversation-level metrics for all of the runs. There is a separate notebook for capturing the run-level metrics. (Each run comprises 5000 conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f92541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53174f45",
   "metadata": {},
   "source": [
    "Each conversation is tagged with a \"theme\", but that tag is only present in the input data. Addionally, each rubric item is tagged with an \"axis\". The axis is available in the results JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the theme for each conversation. This dataframe will be joined into\n",
    "# the rest of the results later on.\n",
    "conversation_input_file = Path(\"inputs/2025-05-07-06-14-12_oss_eval.jsonl\")\n",
    "conversation_lines = conversation_input_file.read_text().split(\"\\n\")\n",
    "\n",
    "\n",
    "def theme_from_conversation(conversation: dict) -> str:\n",
    "    for tag in conversation[\"example_tags\"]:\n",
    "        if tag.startswith(\"theme\"):\n",
    "            return tag.split(\":\")[1]\n",
    "    raise ValueError(\n",
    "        f\"Conversation does not have theme: {conversation['example_tags']}. {conversation['prompt_id']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "rows = []\n",
    "for conversation_line in conversation_lines:\n",
    "    if conversation_line == \"\":\n",
    "        continue\n",
    "    conversation = json.loads(conversation_line)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"conversation_id\": conversation[\"prompt_id\"],\n",
    "            \"theme\": theme_from_conversation(conversation),\n",
    "        }\n",
    "    )\n",
    "themes = pl.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dirs = [\n",
    "    Path(\"5df4ba309cb03369f6663786ae6a9904385524a9/maverick\"),\n",
    "    Path(\"5df4ba309cb03369f6663786ae6a9904385524a9/scout\"),\n",
    "    Path(\"328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3\"),\n",
    "    Path(\"9252fc34f9bc391262e8b71138ee3b86e7d0ad7a/o3\"),\n",
    "    Path(\"9eb82b46b5ef7faf6ec102a989421543e84d4228/llama-3.1-8b\"),\n",
    "]\n",
    "result_files = []\n",
    "for path in results_dirs:\n",
    "    files = list(path.glob(\"*_allresults.json\"))\n",
    "    result_files.extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f16de7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_153644_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_211736_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251027_165626_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/maverick/healthbench_llama-4-maverick_20251023_212754_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251026_154748_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_144601_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_104623_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_140350_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_091851_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251026_005928_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_170346_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251027_115249_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251023_153707_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/5df4ba309cb03369f6663786ae6a9904385524a9/scout/healthbench_llama-4-scout_20251024_161630_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_035734_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_225911_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_004114_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_234852_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_021752_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_205737_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_012947_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_162900_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251029_030629_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/328b8ce1d49f3834a8d91db014ca8de3e95e77f8/llama-3.3/healthbench_llama-3.3-70b_20251028_213700_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/9252fc34f9bc391262e8b71138ee3b86e7d0ad7a/o3/healthbench_o3_20251029_151631_allresults.json'),\n",
       " PosixPath('/Users/max/Developer/repos/HealthBench/results/9eb82b46b5ef7faf6ec102a989421543e84d4228/llama-3.1-8b/healthbench_llama-3.1-8b_20251030_123814_allresults.json')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db6d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name_and_execution_time(results: Path) -> tuple[str, str]:\n",
    "    _, model, day, time, _ = results.stem.split(\"_\")\n",
    "    return model, f\"{day}_{time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de4c371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_from_rubric_item(rubric_item: dict) -> str:\n",
    "    for tag in rubric_item[\"tags\"]:\n",
    "        if tag.startswith(\"axis\"):\n",
    "            return tag.split(\":\")[1]\n",
    "    raise ValueError(\n",
    "        f\"Unable to find axis for rubric item. Tags: {rubric_item['tags']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "rows = []\n",
    "for filepath in result_files:\n",
    "    model, run_id = get_model_name_and_execution_time(filepath)\n",
    "    run_results = json.loads(filepath.read_text())\n",
    "    for conversation_results in run_results[\"metadata\"][\"example_level_metadata\"]:\n",
    "        for rubric_item_index, rubric_item in enumerate(\n",
    "            conversation_results[\"rubric_items\"]\n",
    "        ):\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"model\": model,\n",
    "                    \"run_id\": run_id,\n",
    "                    \"conversation_id\": conversation_results[\"prompt_id\"],\n",
    "                    \"rubric_criterion_index\": rubric_item_index,\n",
    "                    \"axis\": axis_from_rubric_item(rubric_item),\n",
    "                    \"points\": rubric_item[\"points\"],\n",
    "                    \"criterion_met\": rubric_item[\"criteria_met\"],\n",
    "                }\n",
    "            )\n",
    "conversation_results = pl.DataFrame(rows).join(themes, on=\"conversation_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac05b1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_488_162, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>conversation_id</th><th>rubric_criterion_index</th><th>axis</th><th>points</th><th>criterion_met</th><th>theme</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>0</td><td>&quot;completeness&quot;</td><td>10</td><td>true</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>1</td><td>&quot;completeness&quot;</td><td>9</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>2</td><td>&quot;context_awareness&quot;</td><td>7</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>3</td><td>&quot;accuracy&quot;</td><td>-10</td><td>false</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_153644&quot;</td><td>&quot;1f548d5b-cd00-49a0-b327-283a2e…</td><td>4</td><td>&quot;completeness&quot;</td><td>8</td><td>true</td><td>&quot;context_seeking&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;e1cf80cd-965e-4a64-b2e3-a95497…</td><td>13</td><td>&quot;context_awareness&quot;</td><td>5</td><td>true</td><td>&quot;emergency_referrals&quot;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>0</td><td>&quot;accuracy&quot;</td><td>9</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>1</td><td>&quot;completeness&quot;</td><td>8</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>2</td><td>&quot;completeness&quot;</td><td>7</td><td>false</td><td>&quot;global_health&quot;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;20251030_123814&quot;</td><td>&quot;68b20b72-f599-4cd0-a724-097d50…</td><td>3</td><td>&quot;accuracy&quot;</td><td>-9</td><td>false</td><td>&quot;global_health&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_488_162, 8)\n",
       "┌────────────┬────────────┬────────────┬────────────┬────────────┬────────┬────────────┬───────────┐\n",
       "│ model      ┆ run_id     ┆ conversati ┆ rubric_cri ┆ axis       ┆ points ┆ criterion_ ┆ theme     │\n",
       "│ ---        ┆ ---        ┆ on_id      ┆ terion_ind ┆ ---        ┆ ---    ┆ met        ┆ ---       │\n",
       "│ str        ┆ str        ┆ ---        ┆ ex         ┆ str        ┆ i64    ┆ ---        ┆ str       │\n",
       "│            ┆            ┆ str        ┆ ---        ┆            ┆        ┆ bool       ┆           │\n",
       "│            ┆            ┆            ┆ i64        ┆            ┆        ┆            ┆           │\n",
       "╞════════════╪════════════╪════════════╪════════════╪════════════╪════════╪════════════╪═══════════╡\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 0          ┆ completene ┆ 10     ┆ true       ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 1          ┆ completene ┆ 9      ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 2          ┆ context_aw ┆ 7      ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ areness    ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 3          ┆ accuracy   ┆ -10    ┆ false      ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆            ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-4-ma ┆ 20251027_1 ┆ 1f548d5b-c ┆ 4          ┆ completene ┆ 8      ┆ true       ┆ context_s │\n",
       "│ verick     ┆ 53644      ┆ d00-49a0-b ┆            ┆ ss         ┆        ┆            ┆ eeking    │\n",
       "│            ┆            ┆ 327-283a2e ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …          ┆ …          ┆ …      ┆ …          ┆ …         │\n",
       "│ llama-3.1- ┆ 20251030_1 ┆ e1cf80cd-9 ┆ 13         ┆ context_aw ┆ 5      ┆ true       ┆ emergency │\n",
       "│ 8b         ┆ 23814      ┆ 65e-4a64-b ┆            ┆ areness    ┆        ┆            ┆ _referral │\n",
       "│            ┆            ┆ 2e3-a95497 ┆            ┆            ┆        ┆            ┆ s         │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-3.1- ┆ 20251030_1 ┆ 68b20b72-f ┆ 0          ┆ accuracy   ┆ 9      ┆ false      ┆ global_he │\n",
       "│ 8b         ┆ 23814      ┆ 599-4cd0-a ┆            ┆            ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-3.1- ┆ 20251030_1 ┆ 68b20b72-f ┆ 1          ┆ completene ┆ 8      ┆ false      ┆ global_he │\n",
       "│ 8b         ┆ 23814      ┆ 599-4cd0-a ┆            ┆ ss         ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-3.1- ┆ 20251030_1 ┆ 68b20b72-f ┆ 2          ┆ completene ┆ 7      ┆ false      ┆ global_he │\n",
       "│ 8b         ┆ 23814      ┆ 599-4cd0-a ┆            ┆ ss         ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "│ llama-3.1- ┆ 20251030_1 ┆ 68b20b72-f ┆ 3          ┆ accuracy   ┆ -9     ┆ false      ┆ global_he │\n",
       "│ 8b         ┆ 23814      ┆ 599-4cd0-a ┆            ┆            ┆        ┆            ┆ alth      │\n",
       "│            ┆            ┆ 724-097d50 ┆            ┆            ┆        ┆            ┆           │\n",
       "│            ┆            ┆ …          ┆            ┆            ┆        ┆            ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴────────────┴────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d1859eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_results.write_csv(\"healthbench_granular_data.tsv\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fd349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586b0f2c",
   "metadata": {},
   "source": [
    "## Calculating Scores\n",
    "The rest of the cells exist to calculate the overall, theme, and axis scores to reproduce what is in the theme_data.csv, axis_data.csv, and JSON result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20044ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_confidence_intervals(scores: pl.Series) -> dict:\n",
    "    scores_np = scores.to_numpy()\n",
    "    mean = np.clip(np.mean(scores_np), 0, 1).item()\n",
    "    upper, lower = np.percentile(\n",
    "        [np.mean(np.random.choice(scores_np, len(scores_np))) for _ in range(1000)],\n",
    "        [2.5, 97.5],\n",
    "    )\n",
    "    return {\"mean\": mean, \"lower_ci\": float(lower), \"upper_ci\": float(upper)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_results = (\n",
    "    conversation_results.vstack(\n",
    "        # Add another copy of the DF where all conversations are duplicated\n",
    "        # under the \"all\" theme, in order to calculate the overall score and CIs\n",
    "        conversation_results.with_columns(pl.lit(\"all\").alias(\"theme\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Determine whether the points should actually be awarded for each criterion\n",
    "        pl.when(\"criterion_met\")\n",
    "        .then(\"points\")\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"criterion_points_awarded\"),\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"theme\", \"conversation_id\")\n",
    "    .agg(\n",
    "        # Calculate the total number of points possible for the conversation\n",
    "        pl.col(\"points\")\n",
    "        .filter(pl.col(\"points\") > 0)\n",
    "        .sum()\n",
    "        .alias(\"conversation_points_possible\"),\n",
    "        # Sum the points awarded for this conversation, note that the score for an\n",
    "        # individual conversation can be negative, but the overall/theme/axis score\n",
    "        # is clipped to a minimum of 0\n",
    "        pl.col(\"criterion_points_awarded\").sum().alias(\"conversation_points_awarded\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Calculate the score for each conversation\n",
    "        (\n",
    "            pl.col(\"conversation_points_awarded\")\n",
    "            / pl.col(\"conversation_points_possible\")\n",
    "        ).alias(\"conversation_score\")\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"theme\")\n",
    "    .agg(\n",
    "        # Calculate a mean with CI at the run level\n",
    "        pl.col(\"conversation_score\")\n",
    "        .map_batches(function=get_mean_and_confidence_intervals, returns_scalar=True)\n",
    "        .alias(\"results_struct\")\n",
    "    )\n",
    "    .unnest(\"results_struct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7982d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (260_000, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>theme</th><th>conversation_id</th><th>conversation_points_awarded</th><th>conversation_points_possible</th><th>conversation_score</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_205737&quot;</td><td>&quot;hedging&quot;</td><td>&quot;472251ad-dd7a-4ea9-965a-37dc12…</td><td>5</td><td>38</td><td>0.131579</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_205737&quot;</td><td>&quot;context_seeking&quot;</td><td>&quot;041e7d49-6aa1-4c56-af79-051d01…</td><td>32</td><td>48</td><td>0.666667</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_004114&quot;</td><td>&quot;context_seeking&quot;</td><td>&quot;4f097549-151a-4844-899a-3c3db5…</td><td>0</td><td>23</td><td>0.0</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_165626&quot;</td><td>&quot;all&quot;</td><td>&quot;bcda6dfc-b4fa-42f1-96af-2e751f…</td><td>0</td><td>51</td><td>0.0</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_004114&quot;</td><td>&quot;hedging&quot;</td><td>&quot;e59dc979-71b3-4702-90f8-d62d1e…</td><td>45</td><td>81</td><td>0.555556</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251026_005928&quot;</td><td>&quot;all&quot;</td><td>&quot;eefd92ef-79df-4b4b-bfdc-fa62bd…</td><td>12</td><td>65</td><td>0.184615</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_165626&quot;</td><td>&quot;health_data_tasks&quot;</td><td>&quot;6314e6ed-65e4-475e-a4ab-fd141d…</td><td>0</td><td>37</td><td>0.0</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251026_154748&quot;</td><td>&quot;all&quot;</td><td>&quot;2ffec207-51b1-439d-8404-165ce4…</td><td>0</td><td>76</td><td>0.0</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_213700&quot;</td><td>&quot;health_data_tasks&quot;</td><td>&quot;6726cc55-d3d3-41bd-95a5-ec1cec…</td><td>19</td><td>47</td><td>0.404255</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_140350&quot;</td><td>&quot;communication&quot;</td><td>&quot;ee1d2b97-f819-42ca-a4b2-7e7966…</td><td>0</td><td>32</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (260_000, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model        ┆ run_id      ┆ theme       ┆ conversatio ┆ conversatio ┆ conversatio ┆ conversatio │\n",
       "│ ---          ┆ ---         ┆ ---         ┆ n_id        ┆ n_points_aw ┆ n_points_po ┆ n_score     │\n",
       "│ str          ┆ str         ┆ str         ┆ ---         ┆ arded       ┆ ssible      ┆ ---         │\n",
       "│              ┆             ┆             ┆ str         ┆ ---         ┆ ---         ┆ f64         │\n",
       "│              ┆             ┆             ┆             ┆ i64         ┆ i64         ┆             │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ llama-3.3-70 ┆ 20251028_20 ┆ hedging     ┆ 472251ad-dd ┆ 5           ┆ 38          ┆ 0.131579    │\n",
       "│ b            ┆ 5737        ┆             ┆ 7a-4ea9-965 ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ a-37dc12…   ┆             ┆             ┆             │\n",
       "│ llama-3.3-70 ┆ 20251028_20 ┆ context_see ┆ 041e7d49-6a ┆ 32          ┆ 48          ┆ 0.666667    │\n",
       "│ b            ┆ 5737        ┆ king        ┆ a1-4c56-af7 ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ 9-051d01…   ┆             ┆             ┆             │\n",
       "│ llama-3.3-70 ┆ 20251029_00 ┆ context_see ┆ 4f097549-15 ┆ 0           ┆ 23          ┆ 0.0         │\n",
       "│ b            ┆ 4114        ┆ king        ┆ 1a-4844-899 ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ a-3c3db5…   ┆             ┆             ┆             │\n",
       "│ llama-4-mave ┆ 20251027_16 ┆ all         ┆ bcda6dfc-b4 ┆ 0           ┆ 51          ┆ 0.0         │\n",
       "│ rick         ┆ 5626        ┆             ┆ fa-42f1-96a ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ f-2e751f…   ┆             ┆             ┆             │\n",
       "│ llama-3.3-70 ┆ 20251029_00 ┆ hedging     ┆ e59dc979-71 ┆ 45          ┆ 81          ┆ 0.555556    │\n",
       "│ b            ┆ 4114        ┆             ┆ b3-4702-90f ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ 8-d62d1e…   ┆             ┆             ┆             │\n",
       "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
       "│ llama-4-scou ┆ 20251026_00 ┆ all         ┆ eefd92ef-79 ┆ 12          ┆ 65          ┆ 0.184615    │\n",
       "│ t            ┆ 5928        ┆             ┆ df-4b4b-bfd ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ c-fa62bd…   ┆             ┆             ┆             │\n",
       "│ llama-4-mave ┆ 20251027_16 ┆ health_data ┆ 6314e6ed-65 ┆ 0           ┆ 37          ┆ 0.0         │\n",
       "│ rick         ┆ 5626        ┆ _tasks      ┆ e4-475e-a4a ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ b-fd141d…   ┆             ┆             ┆             │\n",
       "│ llama-4-scou ┆ 20251026_15 ┆ all         ┆ 2ffec207-51 ┆ 0           ┆ 76          ┆ 0.0         │\n",
       "│ t            ┆ 4748        ┆             ┆ b1-439d-840 ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ 4-165ce4…   ┆             ┆             ┆             │\n",
       "│ llama-3.3-70 ┆ 20251028_21 ┆ health_data ┆ 6726cc55-d3 ┆ 19          ┆ 47          ┆ 0.404255    │\n",
       "│ b            ┆ 3700        ┆ _tasks      ┆ d3-41bd-95a ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ 5-ec1cec…   ┆             ┆             ┆             │\n",
       "│ llama-4-scou ┆ 20251027_14 ┆ communicati ┆ ee1d2b97-f8 ┆ 0           ┆ 32          ┆ 0.0         │\n",
       "│ t            ┆ 0350        ┆ on          ┆ 19-42ca-a4b ┆             ┆             ┆             │\n",
       "│              ┆             ┆             ┆ 2-7e7966…   ┆             ┆             ┆             │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8fefeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>theme</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;all&quot;</td><td>0.248817</td><td>0.259437</td><td>0.238414</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;communication&quot;</td><td>0.327913</td><td>0.354857</td><td>0.300975</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;complex_responses&quot;</td><td>0.277469</td><td>0.32157</td><td>0.232058</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;context_seeking&quot;</td><td>0.146587</td><td>0.174102</td><td>0.119266</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;emergency_referrals&quot;</td><td>0.411371</td><td>0.449624</td><td>0.374191</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;global_health&quot;</td><td>0.144872</td><td>0.164754</td><td>0.125622</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;health_data_tasks&quot;</td><td>0.289996</td><td>0.327951</td><td>0.25115</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;hedging&quot;</td><td>0.242986</td><td>0.262826</td><td>0.220866</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 6)\n",
       "┌───────────────┬─────────────────┬─────────────────────┬──────────┬──────────┬──────────┐\n",
       "│ model         ┆ run_id          ┆ theme               ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---           ┆ ---             ┆ ---                 ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str           ┆ str             ┆ str                 ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═══════════════╪═════════════════╪═════════════════════╪══════════╪══════════╪══════════╡\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ all                 ┆ 0.248817 ┆ 0.259437 ┆ 0.238414 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ communication       ┆ 0.327913 ┆ 0.354857 ┆ 0.300975 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ complex_responses   ┆ 0.277469 ┆ 0.32157  ┆ 0.232058 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ context_seeking     ┆ 0.146587 ┆ 0.174102 ┆ 0.119266 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ emergency_referrals ┆ 0.411371 ┆ 0.449624 ┆ 0.374191 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ global_health       ┆ 0.144872 ┆ 0.164754 ┆ 0.125622 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ health_data_tasks   ┆ 0.289996 ┆ 0.327951 ┆ 0.25115  │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ hedging             ┆ 0.242986 ┆ 0.262826 ┆ 0.220866 │\n",
       "└───────────────┴─────────────────┴─────────────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results.filter(\n",
    "    (pl.col(\"model\") == \"llama-4-scout\") & (pl.col(\"run_id\") == \"20251024_161630\")\n",
    ").sort(by=\"theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2823cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_results = (\n",
    "    conversation_results.vstack(\n",
    "        # Add another copy of the DF where all conversations a duplicated under the\n",
    "        # \"all\" theme, in order to calculate the overall score and CI\n",
    "        conversation_results.with_columns(pl.lit(\"all\").alias(\"axis\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Determine whether the points should actually be awarded for each criterion\n",
    "        pl.when(\"criterion_met\")\n",
    "        .then(\"points\")\n",
    "        .otherwise(pl.lit(0))\n",
    "        .alias(\"criterion_points_awarded\"),\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"axis\", \"conversation_id\")\n",
    "    .agg(\n",
    "        # Calculate the total number of points possible for the conversation\n",
    "        pl.col(\"points\")\n",
    "        .filter(pl.col(\"points\") > 0)\n",
    "        .sum()\n",
    "        .alias(\"conversation_points_possible\"),\n",
    "        # Sum the points awarded for this quesiton, note that the score for an\n",
    "        # individual question can be negative, but the overall/theme/axis score\n",
    "        # is clipped to a minimum of 0\n",
    "        pl.col(\"criterion_points_awarded\").sum().alias(\"conversation_points_awarded\"),\n",
    "    )\n",
    "    # Filter out questions that do not have any criteria for a given axis\n",
    "    .filter(pl.col(\"conversation_points_possible\") > 0)\n",
    "    .with_columns(\n",
    "        # Calculate the score for each conversation\n",
    "        (\n",
    "            pl.col(\"conversation_points_awarded\")\n",
    "            / pl.col(\"conversation_points_possible\")\n",
    "        ).alias(\"conversation_score\")\n",
    "    )\n",
    "    .group_by(\"model\", \"run_id\", \"axis\")\n",
    "    .agg(\n",
    "        # Calculate a mean with CI at the run level\n",
    "        pl.col(\"conversation_score\")\n",
    "        .map_batches(function=get_mean_and_confidence_intervals, returns_scalar=True)\n",
    "        .alias(\"results_struct\")\n",
    "    )\n",
    "    .unnest(\"results_struct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fda0a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>axis</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;accuracy&quot;</td><td>0.380528</td><td>0.372354</td><td>0.388701</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;all&quot;</td><td>0.248817</td><td>0.243258</td><td>0.254377</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;communication_quality&quot;</td><td>0.655078</td><td>0.643244</td><td>0.666912</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;completeness&quot;</td><td>0.114009</td><td>0.105132</td><td>0.122887</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;context_awareness&quot;</td><td>0.248394</td><td>0.236761</td><td>0.260027</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;instruction_following&quot;</td><td>0.477346</td><td>0.459662</td><td>0.495031</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 6)\n",
       "┌───────────────┬─────────────────┬───────────────────────┬──────────┬──────────┬──────────┐\n",
       "│ model         ┆ run_id          ┆ axis                  ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---           ┆ ---             ┆ ---                   ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str           ┆ str             ┆ str                   ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═══════════════╪═════════════════╪═══════════════════════╪══════════╪══════════╪══════════╡\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ accuracy              ┆ 0.380528 ┆ 0.372354 ┆ 0.388701 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ all                   ┆ 0.248817 ┆ 0.243258 ┆ 0.254377 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ communication_quality ┆ 0.655078 ┆ 0.643244 ┆ 0.666912 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ completeness          ┆ 0.114009 ┆ 0.105132 ┆ 0.122887 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ context_awareness     ┆ 0.248394 ┆ 0.236761 ┆ 0.260027 │\n",
       "│ llama-4-scout ┆ 20251024_161630 ┆ instruction_following ┆ 0.477346 ┆ 0.459662 ┆ 0.495031 │\n",
       "└───────────────┴─────────────────┴───────────────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis_results.filter(\n",
    "    (pl.col(\"model\") == \"llama-4-scout\") & (pl.col(\"run_id\") == \"20251024_161630\")\n",
    ").sort(\"axis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026be5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (156, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>run_id</th><th>theme_or_axis</th><th>theme_or_axis_name</th><th>mean</th><th>lower_ci</th><th>upper_ci</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_012947&quot;</td><td>&quot;axis&quot;</td><td>&quot;all&quot;</td><td>0.246996</td><td>0.24163</td><td>0.252362</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_161630&quot;</td><td>&quot;axis&quot;</td><td>&quot;all&quot;</td><td>0.248817</td><td>0.243258</td><td>0.254377</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_205737&quot;</td><td>&quot;axis&quot;</td><td>&quot;accuracy&quot;</td><td>0.3697</td><td>0.361509</td><td>0.377891</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251029_030629&quot;</td><td>&quot;axis&quot;</td><td>&quot;accuracy&quot;</td><td>0.376129</td><td>0.367866</td><td>0.384392</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251024_144601&quot;</td><td>&quot;axis&quot;</td><td>&quot;instruction_following&quot;</td><td>0.472583</td><td>0.454868</td><td>0.490298</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_165626&quot;</td><td>&quot;axis&quot;</td><td>&quot;completeness&quot;</td><td>0.096537</td><td>0.087927</td><td>0.105146</td></tr><tr><td>&quot;llama-4-scout&quot;</td><td>&quot;20251027_104623&quot;</td><td>&quot;axis&quot;</td><td>&quot;completeness&quot;</td><td>0.117148</td><td>0.107631</td><td>0.126666</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_213700&quot;</td><td>&quot;axis&quot;</td><td>&quot;all&quot;</td><td>0.245781</td><td>0.240343</td><td>0.25122</td></tr><tr><td>&quot;llama-4-maverick&quot;</td><td>&quot;20251027_165626&quot;</td><td>&quot;axis&quot;</td><td>&quot;communication_quality&quot;</td><td>0.682917</td><td>0.671113</td><td>0.69472</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;20251028_162900&quot;</td><td>&quot;axis&quot;</td><td>&quot;completeness&quot;</td><td>0.116597</td><td>0.107824</td><td>0.12537</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (156, 7)\n",
       "┌────────────────┬────────────────┬───────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
       "│ model          ┆ run_id         ┆ theme_or_axis ┆ theme_or_axis ┆ mean     ┆ lower_ci ┆ upper_ci │\n",
       "│ ---            ┆ ---            ┆ ---           ┆ _name         ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str            ┆ str            ┆ str           ┆ ---           ┆ f64      ┆ f64      ┆ f64      │\n",
       "│                ┆                ┆               ┆ str           ┆          ┆          ┆          │\n",
       "╞════════════════╪════════════════╪═══════════════╪═══════════════╪══════════╪══════════╪══════════╡\n",
       "│ llama-3.3-70b  ┆ 20251029_01294 ┆ axis          ┆ all           ┆ 0.246996 ┆ 0.24163  ┆ 0.252362 │\n",
       "│                ┆ 7              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-4-scout  ┆ 20251024_16163 ┆ axis          ┆ all           ┆ 0.248817 ┆ 0.243258 ┆ 0.254377 │\n",
       "│                ┆ 0              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-3.3-70b  ┆ 20251028_20573 ┆ axis          ┆ accuracy      ┆ 0.3697   ┆ 0.361509 ┆ 0.377891 │\n",
       "│                ┆ 7              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-3.3-70b  ┆ 20251029_03062 ┆ axis          ┆ accuracy      ┆ 0.376129 ┆ 0.367866 ┆ 0.384392 │\n",
       "│                ┆ 9              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-4-scout  ┆ 20251024_14460 ┆ axis          ┆ instruction_f ┆ 0.472583 ┆ 0.454868 ┆ 0.490298 │\n",
       "│                ┆ 1              ┆               ┆ ollowing      ┆          ┆          ┆          │\n",
       "│ …              ┆ …              ┆ …             ┆ …             ┆ …        ┆ …        ┆ …        │\n",
       "│ llama-4-maveri ┆ 20251027_16562 ┆ axis          ┆ completeness  ┆ 0.096537 ┆ 0.087927 ┆ 0.105146 │\n",
       "│ ck             ┆ 6              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-4-scout  ┆ 20251027_10462 ┆ axis          ┆ completeness  ┆ 0.117148 ┆ 0.107631 ┆ 0.126666 │\n",
       "│                ┆ 3              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-3.3-70b  ┆ 20251028_21370 ┆ axis          ┆ all           ┆ 0.245781 ┆ 0.240343 ┆ 0.25122  │\n",
       "│                ┆ 0              ┆               ┆               ┆          ┆          ┆          │\n",
       "│ llama-4-maveri ┆ 20251027_16562 ┆ axis          ┆ communication ┆ 0.682917 ┆ 0.671113 ┆ 0.69472  │\n",
       "│ ck             ┆ 6              ┆               ┆ _quality      ┆          ┆          ┆          │\n",
       "│ llama-3.3-70b  ┆ 20251028_16290 ┆ axis          ┆ completeness  ┆ 0.116597 ┆ 0.107824 ┆ 0.12537  │\n",
       "│                ┆ 0              ┆               ┆               ┆          ┆          ┆          │\n",
       "└────────────────┴────────────────┴───────────────┴───────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = axis_results.select(\n",
    "    \"model\",\n",
    "    \"run_id\",\n",
    "    pl.lit(\"axis\").alias(\"theme_or_axis\"),\n",
    "    pl.col(\"axis\").alias(\"theme_or_axis_name\"),\n",
    "    \"mean\",\n",
    "    \"lower_ci\",\n",
    "    \"upper_ci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d00e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-evals (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
